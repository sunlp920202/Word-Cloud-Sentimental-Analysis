{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d48927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to read the teacher observation note more effeciently. Practice a way to extracting, grouping the text data into information\n",
    "#Referencing Source A: https://www.kaggle.com/code/tejashpopate/text-mining-in-python. Referencing Source B:https://towardsai.net/p/data-mining/text-mining-in-python-steps-and-examples-78b3f8fd913b\n",
    "#Further mining the topic of the text: https://monkeylearn.com/topic-analysis/. Text Classification:https://realpython.com/python-keras-text-classification/\n",
    "#Training Dataset: SchoolMintGrow QuickFeedback observation\n",
    "#Training Maetrial : https://portal.smarterbalanced.org/library/en/ela-construct-relevant-vocabulary.pdf\n",
    "#Testing Dataset: SchoolMintGrow Teacher Observation\n",
    "#Project Roadmap:Stage 1, successfully tested on Glow - Glow with Word Cloud and LDA Topic Extracting on sampled data set\n",
    "                #Stage 2, Test on Grow - Grow.\n",
    "                #Stage 3, Test on full data set with Glow -Glow and Grow - Grow.\n",
    "                #Stage 4, Test on survey response to replicate, optimize, clean the code book.\n",
    "                #Stage 5, Continue build up the model with clustering model, the data set needs to be trained(Categorized).\n",
    "                #Stage 6, Apply the trained clustered model to new testing data source to automatically assign the category by the machine. Quality check manually.\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103223e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textblob\n",
    "!pip install vaderSentiment\n",
    "!pip install textmining3\n",
    "!pip3 install wordcloud\n",
    "#import gensim\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "Analyzer = SentimentIntensityAnalyzer()\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "import textmining\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from gensim.utils import simple_preprocess\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "# set the working dierectory\n",
    "\n",
    "df = pd.read_excel('/Users/lipingsun/Desktop/wcpa/Teacher Evaluation/Feedback Activity.xlsx')\n",
    "df['Glow - Glow']=df['Glow - Glow'].astype('str')\n",
    "\n",
    "output='/Users/lipingsun/Desktop/wcpa/Teacher Evaluation/Output_SMG_tableau.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ffb669",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07f4ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    ">>> nltk.download()\n",
    "# define the stopwords and also import predefined ones\n",
    "stop=set(stopwords.words(\"english\"))\n",
    "# Extract punctuation marks\n",
    "punct_exclude=set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e0b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    ">>> brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f79455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform preoprocessing using function below\n",
    "def clean(doc):\n",
    "    stop_free=\" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punct_free=''.join(ch for ch in stop_free if ch not in punct_exclude)\n",
    "    num_free=''.join(i for i in punct_free if not i.isdigit())\n",
    "    return num_free\n",
    "####Column index 4(Glow to Glow). There is a problem of using the index 5(Grow to Grow) or 6(Action Steps) because there are some blank values.\n",
    "####Need to address that either through the raw data file or through the data selection by eleminating the Nulls:dropping rows where 'Review Text' is null\n",
    "#df.dropna(subset=['Grow - Grow'], inplace=True)\n",
    "post_corpus=[clean(df.iloc[i,6]) for i in range(0,df.shape[0])] ###1/4Change the iloc to appropriate index number to switch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a922b3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(post_corpus))\n",
    "print(post_corpus[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba2308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create term document matrix\n",
    "tdm=textmining.TermDocumentMatrix() # use a function from textmining library\n",
    "for i in post_corpus:\n",
    "    #print(i)\n",
    "    tdm.add_doc(i)# update the matrix with each variable conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f064d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386dc6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output='/Users/lipingsun/Desktop/wcpa/Teacher Evaluation/Output_smg_tableau.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a307e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write tdm into dataframe\n",
    "tdm.write_csv(\"TDM_DataFrame.csv\",cutoff= 1) #cutoff won't consider 1st line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbf38d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildMatrix(self,document_list):\n",
    "        print(\"building matrix...\")\n",
    "        tdm = textmining.TermDocumentMatrix()\n",
    "        for doc in document_list:\n",
    "             tdm.add_doc(doc)\n",
    "        #write tdm into dataframe\n",
    "        tdm.write_csv(r'path\\matrix.csv', cutoff=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d2aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result=pd.read_csv(\"TDM_DataFrame.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe42e711",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca32a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8cd462",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef310d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot wordcloud\n",
    "wordcloud= WordCloud(width=1000,height=500, stopwords=STOPWORDS, background_color='white').generate(''.join(df['Grow - Grow'])) ###2/4Change the column name to appropriate one to switch\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0aee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentimental Analysis\n",
    "FinalResult=pd.DataFrame()\n",
    "for i in range(0,df.shape[0]):\n",
    "    #print(i)\n",
    "    blob=TextBlob(df.iloc[i,6]) ###3/4Change the iloc to appropriate index number to switch\n",
    "    temp=pd.DataFrame({\"Comments for Glow\":df.iloc[i,6],\"compound\":blob.sentiment.polarity},index=[0])\n",
    "    FinalResult=FinalResult.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9ad946",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FinalResult.shape)\n",
    "FinalResult[:10]\n",
    "vs= Analyzer.polarity_scores(\"Vader sentiment looks interesting, I have high hopes!\")\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec1b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FinalResult.head()\n",
    "FinalResult[:30]\n",
    "FinalResult.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb44facf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Option 1: Follow the steps here to LDA Topic Modeling.\n",
    "#https://www.analyticsvidhya.com/blog/2021/07/topic-modelling-with-lda-a-hands-on-introduction/?#h2_3\n",
    "from nltk.corpus import stopwords  #stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer  \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "stop_words=set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "\n",
    "def clean_text(headline):\n",
    "      le=WordNetLemmatizer()\n",
    "      word_tokens=word_tokenize(headline)\n",
    "      tokens=[le.lemmatize(w) for w in word_tokens if w not in stop_words and len(w)>3]\n",
    "      cleaned_text=\" \".join(tokens)\n",
    "      return cleaned_text\n",
    "df['cleaned_text']=df['Grow - Grow'].apply(clean_text)###4/4Change the column name to appropriate one to switch\n",
    "df[:10]\n",
    "\n",
    "vect =TfidfVectorizer(stop_words=stop_words,max_features=1000)\n",
    "vect_text=vect.fit_transform(df['cleaned_text'])\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda_model=LatentDirichletAllocation(n_components=5,\n",
    "learning_method='online',random_state=42,max_iter=1) #n_components = topic #\n",
    "lda_top=lda_model.fit_transform(vect_text)\n",
    "print(\"Document 18: \")\n",
    "for i,topic in enumerate(lda_top[18]): \n",
    "  print(\"Topic \",i,\": \",topic*100,\"%\")\n",
    "\n",
    "vocab = vect.get_feature_names()\n",
    "for i, comp in enumerate(lda_model.components_):\n",
    "     vocab_comp = zip(vocab, comp)\n",
    "     sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10] #lda_top = # of words to describe the topics\n",
    "     print(\"Topic \"+str(i)+\": \")\n",
    "     for t in sorted_words:\n",
    "            print(t[0],end=\" \")\n",
    "            print(\"n\")\n",
    "lda_top[:20]\n",
    "#Glow\n",
    "#Topic 0: Ways of suppurt to help students learn during the class(scratch pad, small group discussion). \n",
    "#Topic 1: Ways of instruction strategy to facilitate the engagement of students to solving the problem(EX. board/ask question).\n",
    "#Topic 2: The learning environment and culture as well as classroom expectations improve the relationship.\n",
    "#Topic 3: Small group, pause to check understanding, clear expectations are effective.\n",
    "#Topic 4: Learning material and supplements setting are important to facilitate at grade-level learning.\n",
    "\n",
    "#Grow(For empty row. I inserted \"EMPTY\" as a placeholder)\n",
    "#Topic 0: Ways of suppurt to help students learn during the class(scratch pad, small group discussion). \n",
    "#Topic 1: Ways of instruction strategy to facilitate the engagement of students to solving the problem(EX. board/ask question).\n",
    "#Topic 2: The learning environment and culture as well as classroom expectations improve the relationship.\n",
    "#Topic 3: Small group, pause to check understanding, clear expectations are effective.\n",
    "#Topic 4: Learning material and supplements setting are important to facilitate at grade-level learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a251745",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=df, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09caff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the Topics and relate back to the texts\n",
    "#https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24\n",
    "#https://storage.googleapis.com/destinationinsight.appspot.com/lda.html#topic=2&lambda=0&term=\n",
    "#USE THIS ONE TO FURTHER INVESTIGATE THE CASE: https://www.kaggle.com/code/panks03/clustering-with-topic-modeling-using-lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe47630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, score in sorted(lda_top[df.['Glow - Glow'][2]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_top.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c7378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write TOPICS Array data to excel file\n",
    "writer = pd.ExcelWriter(output)\n",
    "\n",
    "pd.DataFrame(lda_top).to_excel(writer, sheet_name='TopicScore',index=False)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f761d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option 2: Follow the steps here to clustering the comments.\n",
    "#https://www.kaggle.com/code/panks03/clustering-with-topic-modeling-using-lda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f5d8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e4f5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option 3: Follow the steps here to LDA Topic Modeling.\n",
    "#https://neptune.ai/blog/pyldavis-topic-modelling-exploration-tool-that-every-nlp-data-scientist-should-know\n",
    "!pip3 install pyldavis\n",
    "import pyLDAvis.gensim_models\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "import gensim.corpora as corpora\n",
    "from gensim.corpora import distionary\n",
    "from gensim.models.cohenrencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from pprint import pprint\n",
    "import spacy\n",
    "import pickle\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# number of topics\n",
    "num_topics = 10\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b3a271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
